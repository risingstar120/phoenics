{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoenics: a universal deep Bayesian optimizer\n",
    "\n",
    "This notebook introduces Phoenics and demonstrates how to use Phoenics for simple optimization problems on parameter domains of arbitrary dimensionality. For further details and more examples, please check out the GitHub repository:\n",
    "\n",
    "[https://github.com/aspuru-guzik-group/phoenics](https://github.com/aspuru-guzik-group/phoenics)\n",
    "\n",
    "Details on the mathematical methods and models implemented in Phoenics can be found at:\n",
    "\n",
    "F. Hase, L.M. Roch, C. Kreisbeck, A. Aspuru-Guzik, Phoenics: a universal deep Bayesian optimizer. (2018) [https://arxiv.org/abs/1801.01469](https://arxiv.org/abs/1801.01469)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import python libraries\n",
    "import sys, json, copy\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "sns.set_context('paper', font_scale = 2.0, rc = {'lines.linewidth': 3})\n",
    "sns.set_style('ticks')\n",
    "%matplotlib inline\n",
    "\n",
    "# import phoenics\n",
    "from phoenics.phoenics import Phoenics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The configuration file\n",
    "\n",
    "Parameters for an optimization procedure need to be provided in a **configuration file** in the jSON format. The configuration file needs to contain general information about the optimization procedure as well as specific information about the variables for which the optimum is to be found.\n",
    "\n",
    "Below is an example of a configuration file for an optimization run with two variables, `param0` and `param1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"general\": {\n",
      "\t\t\"num_batches\": 1,\n",
      "\t\t\"batch_size\": 3\n",
      "\t},\n",
      "\t\"variables\": [{\"param0\": { \"low\": -4.0,  \"high\": 2.0,   \"type\": \"float\",  \"size\": 2} }, \n",
      "\t\t\t\t  {\"param1\": { \"low\": 30.0,  \"high\": 60.0,  \"type\": \"float\",  \"size\": 3} }]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the configuration file\n",
    "config_file = 'my_experiment.txt'\n",
    "print(open(config_file, 'r').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'general'` keyword is used to define general information about the optimization procedure:\n",
    "* `num_batches`: The default number of parameter sets to be proposed in one optimization iteration\n",
    "* `batch_size`: The default number of parameter sets proposed from different sampling strategies in a single batch\n",
    "\n",
    "The '`variables'` keyword is used to define specific information about all variables which need to be optimized. This keyword expects a list of all variables on which the optimization procedure is supposed to be run:\n",
    "* '`param0`': example for the unique name of a variable. You may choose your favorite names for all variables, but variable names **must** be unique!\n",
    "* '`low`': lower bound for this variable (inclusive)\n",
    "* '`high`': upper bound for this variable (inclusive)\n",
    "* '`type`': variable type (only `'float'` is supported at this point)\n",
    "* '`size`': size of this variable; must be an integer greater than or equal to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing an instance of Phoenics\n",
    "\n",
    "The configuration file now allows for easy initialization of an instance of Phoenics as it is demonstrated in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an instance of Phoenics\n",
    "phoenics = Phoenics(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phoenics automatically parses all information provided in the configuration file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'num_batches': 1, 'batch_size': 3}, 'variables': [{'param0': {'low': -4.0, 'high': 2.0, 'type': 'float', 'size': 2}}, {'param1': {'low': 30.0, 'high': 60.0, 'type': 'float', 'size': 3}}]}\n"
     ]
    }
   ],
   "source": [
    "# phoenics automatically parses the configuration file\n",
    "print(phoenics.param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling new parameter sets for querying the objective\n",
    "\n",
    "An instance of Phoenics can then be used to propose new parameter sets at which the objective function should be evaluated to discover the global optimimum. Phoenics can run in two different modes, corresponding to two different scenarios:\n",
    "\n",
    "* **no observations available**: This case might correspond to scenarios in which the experiment is just initialized. The objective function has not been evaluated yet and no prior knowledge about the landscape is available. In this case, Phoenics acts as a uniform random sampler for all declared parameters\n",
    "\n",
    "* **observations available**: In this case, the objective function has been evaluated at a number of parameter points already, which provides information about the landscape of the objective function. Phoenics exploits this knowledge to propose new parameter points for querying the objective function and discovering the global optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No observations available\n",
    "\n",
    "First, let's consider a case in which we do not have any knowledge about the objective function landscape. Parameter sets can always be requested with the `choose` method. Simply calling the `choose` method without providing any additional arguments generates as many parameter sets as were specified with the `num_batches` option in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'param0': {'samples': array([-3.84800641, -2.8484572 ])}, 'param1': {'samples': array([ 30.1702323 ,  49.66706259,  50.98872368])}}]\n"
     ]
    }
   ],
   "source": [
    "# phoenics is a uniform random sampler without any observations\n",
    "sampled_params = phoenics.choose()\n",
    "print(sampled_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `choose` method returns a list of python dictionaries with information about the sampled parameter points.\n",
    "\n",
    "Phoenics also allows us to deviate from the initial settings. With the `num_samples` argument, the number of proposed parameter sets can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'param0': {'samples': array([ 1.95654646, -1.10101855])}, 'param1': {'samples': array([ 42.95136195,  40.99273375,  44.48832017])}}\n",
      "{'param0': {'samples': array([-1.72039787, -2.17098636])}, 'param1': {'samples': array([ 55.71303832,  49.65954287,  34.3424954 ])}}\n",
      "{'param0': {'samples': array([ 1.06541465,  0.94323606])}, 'param1': {'samples': array([ 36.57336715,  53.37726152,  56.63508027])}}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100691)\n",
    "# you can get as many samples as you like\n",
    "sampled_params = phoenics.choose(num_samples = 3)\n",
    "for sample in sampled_params:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of returning sampled parameter points allows for easy matching of sampled numbers and corresponding variables. However, should this option be inconvenient for you, you can also ask Phoenics to return the sampled parameters as a numpy array. To do so, simply call `choose` with the `as_array` argument set to `True`. Note, that elements along the second dimension are listed in their order of appearance in the configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.95654646  -1.10101855  42.95136195  40.99273375  44.48832017]\n",
      "[ -1.72039787  -2.17098636  55.71303832  49.65954287  34.3424954 ]\n",
      "[  1.06541465   0.94323606  36.57336715  53.37726152  56.63508027]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100691)\n",
    "# phoenics can also return just parameter arrays\n",
    "sampled_params_array = phoenics.choose(num_samples = 3, as_array = True)\n",
    "for sample in sampled_params_array:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations available\n",
    "\n",
    "Running Phoenics when information about the objective function are available. Phoenics expects observations to be provided in a similar format as sampled parameter sets are returned by the `choose` method.\n",
    "\n",
    "Observations need to be provided as a list of dictionaries, where for each dictionary the key is the unique variable name, the observed parameter values for this variable are stored at `'samples'` and the observed objective function value is stored at `'loss'`. An example for how to generate a valid list of observations is provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's fake a loss function for phoenics\n",
    "evaluated_params = copy.deepcopy(sampled_params)\n",
    "prior_losses = []\n",
    "for sample_dict in evaluated_params:\n",
    "    # calculate a dummy loss \n",
    "    loss = np.linalg.norm(sample_dict['param0']['samples']) + np.linalg.norm(sample_dict['param1']['samples'])\n",
    "    prior_losses.append(loss)\n",
    "    # store loss in the dictionary at the 'loss' keyword\n",
    "    sample_dict['loss'] = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the generated list of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'param0': {'samples': array([ 1.95654646, -1.10101855])}, 'param1': {'samples': array([ 42.95136195,  40.99273375,  44.48832017])}, 'loss': 76.436939989369804}\n",
      "{'param0': {'samples': array([-1.72039787, -2.17098636])}, 'param1': {'samples': array([ 55.71303832,  49.65954287,  34.3424954 ])}, 'loss': 84.924861862048374}\n",
      "{'param0': {'samples': array([ 1.06541465,  0.94323606])}, 'param1': {'samples': array([ 36.57336715,  53.37726152,  56.63508027])}, 'loss': 87.412929138315519}\n"
     ]
    }
   ],
   "source": [
    "for evaluation in evaluated_params:\n",
    "    print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Phoenics currently only supports **minimizations**! If you would rather like to maximize a certain objective, make sure to provide the negative objective function value.\n",
    "\n",
    "The list of observations can now be used to request new parameter points for querying the objective function taking into account the acquired knowledge about the objective function landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# running density estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "100%|██████████| 1500/1500 [00:15<00:00, 95.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# proposing new samples\n",
      "# ... optimizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting process for  0\n",
      "starting process for  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting process for  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-3:\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 88, in _proposal_optimization_thread\n",
      "    res = minimize(penalty, sample, method = 'L-BFGS-B', options = {'maxiter': 25})\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/_minimize.py\", line 450, in minimize\n",
      "    callback=callback, **options)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 328, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 88, in _proposal_optimization_thread\n",
      "    res = minimize(penalty, sample, method = 'L-BFGS-B', options = {'maxiter': 25})\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 273, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 88, in _proposal_optimization_thread\n",
      "    res = minimize(penalty, sample, method = 'L-BFGS-B', options = {'maxiter': 25})\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/_minimize.py\", line 450, in minimize\n",
      "    callback=callback, **options)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 328, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/_minimize.py\", line 450, in minimize\n",
      "    callback=callback, **options)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 273, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 80, in penalty\n",
      "    num, den = self.penalty_contributions(x)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 328, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"../phoenics/BayesianNeuralNetwork/bayesian_neural_network.py\", line 76, in penalty_contributions\n",
      "    num, den = self.dist_evaluator.get_penalty(x)\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/lbfgsb.py\", line 273, in func_and_grad\n",
      "    f = fun(x, *args)\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 80, in penalty\n",
      "    num, den = self.penalty_contributions(x)\n",
      "  File \"../phoenics/BayesianNeuralNetwork/bayesian_neural_network.py\", line 76, in penalty_contributions\n",
      "    num, den = self.dist_evaluator.get_penalty(x)\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 86, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 86, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 90, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "  File \"/home/flo/anaconda3/envs/phoenics/lib/python3.6/site-packages/scipy/optimize/optimize.py\", line 292, in function_wrapper\n",
      "    return function(*(wrapper_args + args))\n",
      "  File \"../phoenics/Acquisitions/sampler.py\", line 80, in penalty\n",
      "    num, den = self.penalty_contributions(x)\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 67, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator._probs\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 90, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "IndexError: Out of bounds on buffer access (axis 0)\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 67, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator._probs\n",
      "IndexError: Out of bounds on buffer access (axis 0)\n",
      "  File \"../phoenics/BayesianNeuralNetwork/bayesian_neural_network.py\", line 76, in penalty_contributions\n",
      "    num, den = self.dist_evaluator.get_penalty(x)\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 86, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 90, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator.get_penalty\n",
      "  File \"phoenics/BayesianNeuralNetwork/dist_evaluations.pyx\", line 67, in BayesianNeuralNetwork.dist_evaluations.DistEvaluator._probs\n",
      "IndexError: Out of bounds on buffer access (axis 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5a02e1f9365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# phoenics now starts sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphoenics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluated_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Phoenics/phoenics_release/phoenics/phoenics.py\u001b[0m in \u001b[0;36mchoose\u001b[0;34m(self, num_samples, observations, as_array)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                         \u001b[0;31m# generating samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_sampled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                         \u001b[0;31m# get the most informative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# selecting informative samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Phoenics/phoenics_release/phoenics/phoenics.py\u001b[0m in \u001b[0;36m_generate_sampled\u001b[0;34m(self, num_samples, observ_dict)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;31m# sample the acquisition function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# proposing new samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposed_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_func_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowest_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty_contributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Phoenics/phoenics_release/phoenics/Acquisitions/sampler.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, current_best, penalty_contributions, lambda_values, num_samples)\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_random_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# ... optimizing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mproposals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Phoenics/phoenics_release/phoenics/Acquisitions/sampler.py\u001b[0m in \u001b[0;36m_optimize_proposals\u001b[0;34m(self, proposals)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                 \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Phoenics/phoenics_release/phoenics/Acquisitions/sampler.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                 \u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# phoenics now starts sampling\n",
    "new_params = phoenics.choose(observations = evaluated_params, as_array = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's compute the losses again\n",
    "post_losses = []\n",
    "for sample in new_params[0]:\n",
    "    # calculate a dummy loss \n",
    "    loss = np.linalg.norm(sample[0:2]) + np.linalg.norm(sample[3:])\n",
    "    post_losses.append(loss)\n",
    "    # store loss in the dictionary at the 'loss' keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and plot the results\n",
    "plt.plot(np.arange(3), prior_losses, marker = 'o', ls = '', color = 'k', markersize = 12, label = 'prior')\n",
    "plt.plot(np.arange(3) + 3, post_losses, marker = 'o', ls = '', markersize = 12, label = 'post')\n",
    "plt.ylim(0, 92)\n",
    "plt.legend()\n",
    "plt.xlabel('# evaluations')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "A typical optimization workflow with Phoenics could consist of the following steps:\n",
    "* generate your configuration file to provide general information and information about the variables to optimize\n",
    "* initialize the optimization procedure by running Phoenics without any observations (optional)\n",
    "* provide a list of observations to Phoenics to exploit acquired knowledge\n",
    "\n",
    "For questions and/or support, please don't hesitate to contact Flo (fhase@g.harvard.edu)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:phoenics]",
   "language": "python",
   "name": "conda-env-phoenics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
